{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DebraBeat/stock_project/blob/main/stock_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MdXLHxFNOk_b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup, SoupStrainer\n",
        "import re\n",
        "import csv\n",
        "from google.colab import drive\n",
        "import os\n",
        "import datetime\n",
        "import time\n",
        "import random\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V6yDnIXmN5l",
        "outputId": "878fa309-da75-4d0a-ac97-090a30e84692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "1585through1588.csv  df19.csv  df2.csv\t df40.csv  df51.csv  df62.csv\t   package-lock.json\n",
            "496through499.csv    df1.csv   df30.csv  df41.csv  df52.csv  df63.csv\t   price_df.csv\n",
            "df0.csv\t\t     df20.csv  df31.csv  df42.csv  df53.csv  df64.csv\t   prices.txt\n",
            "df10.csv\t     df21.csv  df32.csv  df43.csv  df54.csv  df65.csv\t   stock_valuations.csv\n",
            "df11.csv\t     df22.csv  df33.csv  df44.csv  df55.csv  df66.csv\t   symbols\n",
            "df12.csv\t     df23.csv  df34.csv  df45.csv  df56.csv  df6.csv\t   test.csv\n",
            "df13.csv\t     df24.csv  df35.csv  df46.csv  df57.csv  df7.csv\n",
            "df14.csv\t     df25.csv  df36.csv  df47.csv  df58.csv  df8.csv\n",
            "df15.csv\t     df26.csv  df37.csv  df48.csv  df59.csv  df9.csv\n",
            "df16.csv\t     df27.csv  df38.csv  df49.csv  df5.csv   df.csv\n",
            "df17.csv\t     df28.csv  df39.csv  df4.csv   df60.csv  download\n",
            "df18.csv\t     df29.csv  df3.csv\t df50.csv  df61.csv  node_modules\n",
            "7159\n",
            "6757\n"
          ]
        }
      ],
      "source": [
        "# Downloaded csv file and locally parsed symbols from here: https://www.nasdaq.com/market-activity/stocks/screener\n",
        "# Code to parse symbols:\n",
        "# import csv\n",
        "# path = r\"C:\\Users\\zeeri\\Downloads\\nasdaq_screener_1717802878001.csv\"\n",
        "# tickers = []\n",
        "\n",
        "# with open(path, newline='') as csvfile:\n",
        "#     reader = csv.reader(csvfile, delimiter=',')\n",
        "\n",
        "#     for row in reader:\n",
        "#         tickers.append(row[0])\n",
        "\n",
        "# print(tickers[1:])\n",
        "\n",
        "# Get symbol data\n",
        "# Run ls to make sure you're in the right directory\n",
        "\n",
        "'''\n",
        "Put ourselves into the google drive directory for our project and get a list\n",
        "of symbols to use\n",
        "'''\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir(\"drive/My Drive/stock_project\")\n",
        "!ls\n",
        "raw_symbols = []\n",
        "symbols = []\n",
        "with open('symbols', 'r') as csvfile:\n",
        "  reader = csv.reader(csvfile, delimiter=',')\n",
        "\n",
        "  for row in reader:\n",
        "    raw_symbols.append(row)\n",
        "\n",
        "# symbols is a 2d list of one element, so make it the first element\n",
        "raw_symbols = raw_symbols[0]\n",
        "\n",
        "# sanitize symbols\n",
        "for symbol in raw_symbols:\n",
        "  if symbol.isalnum():\n",
        "    symbols.append(symbol)\n",
        "\n",
        "print(len(raw_symbols))\n",
        "print(len(symbols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDJTu0_vm41s"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Define our user agent so yahoo finance doesn't think we're a web crawler.\n",
        "Define the key parts of our URL to request\n",
        "'''\n",
        "header = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'}\n",
        "\n",
        "head = 'https://finance.yahoo.com/quote/'\n",
        "stats_tail = '/key-statistics/'\n",
        "hist_tail = 'history?period1=942883200&period2=1717718400&interval=1mo&filter=history&frequency=1mo&includeAdjustedClose=true'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOsp0TpYoCf1"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This cell is a prototype / test of fetching data from yahoo finance, to be used below.\n",
        "Make sure to run this to create table_elements\n",
        "'''\n",
        "\n",
        "\n",
        "# response = requests.get('https://finance.yahoo.com/quote/NVDA/key-statistics/', headers=header)\n",
        "response = requests.get(head + 'NVDA' + stats_tail, headers=header)\n",
        "print(head + symbols[0] + stats_tail)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "data_cells = soup.find_all('td')\n",
        "table_elements = []\n",
        "\n",
        "for tag in data_cells:\n",
        "  table_elements.append(tag.contents[0])\n",
        "print(table_elements)\n",
        "\n",
        "for i, s in enumerate(table_elements):\n",
        "  try:\n",
        "    if s[0].isalpha():\n",
        "      # print(f'{s}: {table_elements[i+1]}')\n",
        "      pass\n",
        "  except KeyError as error:\n",
        "    # print('--')\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEBDhEuDu68u"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This cell is a prototype / test of creation of the statistics dataframe, to be used below.\n",
        "'''\n",
        "\n",
        "cols = ['Company']\n",
        "d = {'Company': symbols[0]}\n",
        "for i, s in enumerate(table_elements):\n",
        "  try:\n",
        "    if s[0].isalpha():\n",
        "      cols.append(s)\n",
        "      d[s] = table_elements[i+1]\n",
        "  except KeyError:\n",
        "    cols.append(np.nan)\n",
        "\n",
        "df = pd.DataFrame(data=d, columns=cols, index=[0])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Esf4ctaFHT9"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Define our function for retriveing stock statistics (AKA data or valuations\n",
        "or metrics). Take in a DataFrame, create a new row for a new stock, and\n",
        "concatenate it onto the end of the DataFrame. Then return the new DataFrame.\n",
        "'''\n",
        "\n",
        "def append_stock_stats(df, symbol, i):\n",
        "  response = requests.get(head + symbol + stats_tail, headers=header)\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  data_cells = soup.find_all('td')\n",
        "  table_elements = []\n",
        "  d = {'Company': symbol}\n",
        "\n",
        "  for tag in data_cells:\n",
        "    try:\n",
        "      table_elements.append(tag.contents[0])\n",
        "    except IndexError as err:\n",
        "      table_elements.append(np.nan)\n",
        "      print(f'{err}')\n",
        "\n",
        "  for j, s in enumerate(table_elements):\n",
        "    try:\n",
        "      if s[0].isalpha() and j < len(table_elements) - 1:\n",
        "        d[s] = table_elements[j+1]\n",
        "    except KeyError:\n",
        "      # print(f'KeyError, Symbol: {symbol}, i: {i}')\n",
        "      # print(f'j: {j}, s: {s}')\n",
        "      pass\n",
        "    except IndexError:\n",
        "      print(f'IndexError, Symbol: {symbol}, i: {i}, j: {j}')\n",
        "      print(f'j: {j}, s: {s}')\n",
        "      raise\n",
        "    except TypeError:\n",
        "      print(f'TypeError, Symbol: {symbol}, i: {i}, j: {j}')\n",
        "      print(f'j: {j}, s: {s}')\n",
        "      raise\n",
        "    except requests.TooManyRedirects:\n",
        "      print(f'TooManyRedirects, Symbol: {symbol}, i: {i}, j: {j}')\n",
        "      print(f'j: {j}, s: {s}')\n",
        "      raise\n",
        "\n",
        "  row = pd.DataFrame(data=d, columns=cols, index=[i])\n",
        "  df = pd.concat([df, row])\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkqz0O-KHNJ2"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Create and populate our DataFrame of stock data.\n",
        "Note this cell takes about 12 hours to run :)\n",
        "'''\n",
        "\n",
        "# Create columns for reference\n",
        "cols = ['Company']\n",
        "for s in table_elements:\n",
        "  try:\n",
        "    if s[0].isalpha():\n",
        "      cols.append(s)\n",
        "  except KeyError:\n",
        "    cols.append(np.nan)\n",
        "\n",
        "# Create empty DataFrame with just column names\n",
        "df = pd.DataFrame(columns=cols)\n",
        "\n",
        "# Populate the DataFrame\n",
        "symbol_index = 100\n",
        "df_num = 58\n",
        "for i in range(0, len(symbols)):\n",
        "  try:\n",
        "    df = append_stock_stats(df, symbols[i], i)\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "\n",
        "  # In case we've used up our allotted requests per whatever,\n",
        "  # we wait, then delete the last row and try again\n",
        "  wait_time = 0\n",
        "  while pd.isna(df['Market Cap'].iloc[-1]):\n",
        "    time.sleep(90 + wait_time)\n",
        "    wait_time += 1\n",
        "    df.drop(df.tail(1).index, inplace=True)\n",
        "    try:\n",
        "      df = append_stock_stats(df, symbols[i], i)\n",
        "    # If for whatever reason we can't get a particular stock's data\n",
        "    # we continue on without it's data\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "  print(f'Row {i} fetched, Current stock: {symbols[i]}')\n",
        "\n",
        "  if i % 100 == 0:\n",
        "    !ls\n",
        "\n",
        "  if i % 99 == 0 and i > 0:\n",
        "    filename = f'df{df_num}.csv'\n",
        "    df_num += 1\n",
        "    df.to_csv(filename)\n",
        "    df = pd.DataFrame(columns=cols)\n",
        "    print(f'stocks {i-100} through {i} written')\n",
        "    !ls\n",
        "\n",
        "\n",
        "  # # Add a random delay because I am unreasonably cautious about getting\\\n",
        "  # # banned from yahoo finance\n",
        "  delay = random.random() * 0.5 + 0.5\n",
        "  time.sleep(delay)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkcWQesjhtRe"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Get the stock metrics csv and clean it up a little. It will be cleaned more after\n",
        "the stock prices have been added\n",
        "'''\n",
        "\n",
        "copy = pd.read_csv('df.csv', index_col=0)\n",
        "\n",
        "for i in range(3, 67):\n",
        "  df = pd.read_csv(f'df{i}.csv', index_col=0)\n",
        "  copy = pd.concat([copy, df], axis=0, join='outer')\n",
        "  print(copy.shape)\n",
        "\n",
        "df = pd.read_csv('1585through1588.csv')\n",
        "copy = pd.concat([copy, df], axis=0, join='outer')\n",
        "df = pd.read_csv('496through499.csv')\n",
        "copy = pd.concat([copy, df], axis=0, join='outer')\n",
        "\n",
        "copy.reset_index()\n",
        "copy.drop(columns=['Unnamed: 0', 'Unnamed: 11'])\n",
        "copy.to_csv('df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1Srzpppnyv-"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Install the program dukascopy-node which will allow us to easily fetch\n",
        "historical stock price data\n",
        "'''\n",
        "\n",
        "subprocess.run([\"npm install dukascopy-node --save\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKTExT07dSyF"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Create the symbols we need to use for dukascopy, and then get stock price data\n",
        "for each company\n",
        "'''\n",
        "dukascopy_symbols = []\n",
        "\n",
        "for symbol in symbols:\n",
        "  dukascopy_symbols.append(symbol.lower() + 'ususd')\n",
        "\n",
        "for symbol in dukascopy_symbols:\n",
        "  string = f'npx dukascopy-node -i {symbol} -from 2023-06-01 -to 2024-06-01 -t mn1 -f csv --date-format \"YYYY-MM-DD HH:mm:ss\"'\n",
        "  subprocess.run([string], shell=True)\n",
        "  print(string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tE2p1qzAlFSJ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Get the names of each csv price file. From this, put them all into one DataFrame.\n",
        "\n",
        "Here's the most devious test cases for filenamesI could think of:\n",
        "filename = 'ususususd-mn1-bid-2023-06-01-2024-06-01.csv'\n",
        "filename = 'aususd-mn1-bid-2023-06-01-2024-06-01.csv'\n",
        "'''\n",
        "!ls download > prices.txt\n",
        "\n",
        "price_df = pd.DataFrame(columns=['symbol', 'timestamp', 'close'])\n",
        "\n",
        "with open('prices.txt', 'r') as f:\n",
        "  lines = f.readlines()\n",
        "  for line in lines:\n",
        "    line = line[:-1]\n",
        "    # print(line)\n",
        "    ticker = line[:-39]\n",
        "    temp = pd.read_csv(filename)\n",
        "    temp = temp[['timestamp', 'close']]\n",
        "    temp.insert(0, 'symbol', ticker)\n",
        "    price_df = pd.concat([price_df, temp])\n",
        "price_df.to_csv('price_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def string_to_dollar(value: str) -> int:\n",
        "  if type(value) != str or value[:2] == '--':\n",
        "    return np.NaN\n",
        "\n",
        "  pre_decimal = 0\n",
        "  post_decimal = 0\n",
        "  figures = {'': 1,\n",
        "             'k': 1000,\n",
        "             'M': 1000000,\n",
        "             'B': 1000000000,\n",
        "             'T': 1000000000000}\n",
        "  i = 0\n",
        "  j = 1\n",
        "\n",
        "  while i < len(value) and value[i].isnumeric():\n",
        "    pre_decimal = pre_decimal * 10 + int(value[i])\n",
        "    i += 1\n",
        "\n",
        "  while i < len(value) and not value[i].isalpha():\n",
        "    if value[i].isnumeric():\n",
        "      post_decimal += int(value[i]) / 10**j\n",
        "      j += 1\n",
        "    i += 1\n",
        "\n",
        "  try:\n",
        "    return (pre_decimal + post_decimal) * figures[value[i]]\n",
        "  except:\n",
        "    return float(value.replace(',', '').strip())\n",
        "\n",
        "# TEST CASES:\n",
        "# print(string_to_dollar('666.56K')) Random one with K instead of M\n",
        "# print(string_to_dollar('38.81B')) A\n",
        "# print(string_to_dollar('7.39B')) AA\n",
        "# print(string_to_dollar('666.56M')) AACT\n",
        "# print(string_to_dollar('2.96T')) AAPL\n",
        "# print(string_to_dollar('--')) None fetched / avaliable"
      ],
      "metadata": {
        "id": "dUPx9lHQrkOL"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def string_to_percent(value):\n",
        "  if type(value) != str or value[:2] == '--':\n",
        "    return np.NaN\n",
        "\n",
        "  value = value.strip()\n",
        "  res_string = ''\n",
        "  for c in value:\n",
        "    if c != ',' and c != '%':\n",
        "      res_string += c\n",
        "\n",
        "  return float(res_string)\n"
      ],
      "metadata": {
        "id": "3vaPGa2jN-HB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Clean up our training data DataFrame\n",
        "'''\n",
        "\n",
        "df = pd.read_csv('df.csv', index_col=0)\n",
        "# Drop rows incorrectly added\n",
        "df.drop(columns=['Unnamed: 0', 'Unnamed: 11'], inplace=True)\n",
        "\n",
        "# Convert from object to string dtypes for all columns\n",
        "df = df.convert_dtypes()\n",
        "\n",
        "# Drop irrelevant column\n",
        "df.drop(columns=['Most Recent Quarter  (mrq)'], inplace=True)\n",
        "\n",
        "# Rename some columns with weird whitespace stuff\n",
        "df.rename(columns={col : col.replace(\" (\", \"(\").strip() for col in df.columns},\n",
        "            inplace=True)\n",
        "\n",
        "# In the dollar columns, convert from string to int (aka dollars)\n",
        "dollar_cols = ['Market Cap', 'Enterprise Value', 'Trailing P/E', 'Forward P/E',\n",
        "               'PEG Ratio(5yr expected)', 'Price/Sales', 'Price/Book',\n",
        "               'Enterprise Value/Revenue', 'Revenue Per Share (ttm)']\n",
        "for column in dollar_cols:\n",
        "  df[column] = df[column].apply(string_to_dollar)\n",
        "\n",
        "# In the datetime columns, convert from string to datetime\n",
        "datetime_cols = ['Fiscal Year Ends']\n",
        "for column in datetime_cols:\n",
        "  df[column] = pd.to_datetime(df[column], errors='coerce')\n",
        "\n",
        "# In the percentage columns, convert from string to float\n",
        "percentage_cols = ['Profit Margin', 'Operating Margin (ttm)',\n",
        "                   'Return on Assets (ttm)', 'Return on Equity (ttm)']\n",
        "for column in percentage_cols:\n",
        "  df[column] = df[column].apply(string_to_percent)\n",
        "df['Revenue Per Share (ttm)']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcY3TnvWoi31",
        "outputId": "4661eb11-1c46-4e1a-a74b-8187034ca2b1"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    22.53\n",
              "1    58.79\n",
              "2     7.06\n",
              "3      NaN\n",
              "4      NaN\n",
              "     ...  \n",
              "4      NaN\n",
              "0     5.82\n",
              "1     1.51\n",
              "2    82.22\n",
              "3     0.03\n",
              "Name: Revenue Per Share (ttm), Length: 6716, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgwXPOcL04gGyp/y4v8QU7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}