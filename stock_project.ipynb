{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DebraBeat/stock_project/blob/main/stock_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdXLHxFNOk_b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup, SoupStrainer\n",
        "import re\n",
        "import csv\n",
        "from google.colab import drive\n",
        "import os\n",
        "import datetime\n",
        "import time\n",
        "import random\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V6yDnIXmN5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fab4059-c450-41a4-dc0a-f3d9003cda7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "1585through1588.csv  df19.csv  df2.csv\t df40.csv  df51.csv  df62.csv\t   package-lock.json\n",
            "496through499.csv    df1.csv   df30.csv  df41.csv  df52.csv  df63.csv\t   price_df.csv\n",
            "df0.csv\t\t     df20.csv  df31.csv  df42.csv  df53.csv  df64.csv\t   prices.txt\n",
            "df10.csv\t     df21.csv  df32.csv  df43.csv  df54.csv  df65.csv\t   stock_valuations.csv\n",
            "df11.csv\t     df22.csv  df33.csv  df44.csv  df55.csv  df66.csv\t   symbols\n",
            "df12.csv\t     df23.csv  df34.csv  df45.csv  df56.csv  df6.csv\t   test.csv\n",
            "df13.csv\t     df24.csv  df35.csv  df46.csv  df57.csv  df7.csv\n",
            "df14.csv\t     df25.csv  df36.csv  df47.csv  df58.csv  df8.csv\n",
            "df15.csv\t     df26.csv  df37.csv  df48.csv  df59.csv  df9.csv\n",
            "df16.csv\t     df27.csv  df38.csv  df49.csv  df5.csv   df.csv\n",
            "df17.csv\t     df28.csv  df39.csv  df4.csv   df60.csv  download\n",
            "df18.csv\t     df29.csv  df3.csv\t df50.csv  df61.csv  node_modules\n",
            "7159\n",
            "6757\n"
          ]
        }
      ],
      "source": [
        "# Downloaded csv file and locally parsed symbols from here: https://www.nasdaq.com/market-activity/stocks/screener\n",
        "# Code to parse symbols:\n",
        "# import csv\n",
        "# path = r\"C:\\Users\\zeeri\\Downloads\\nasdaq_screener_1717802878001.csv\"\n",
        "# tickers = []\n",
        "\n",
        "# with open(path, newline='') as csvfile:\n",
        "#     reader = csv.reader(csvfile, delimiter=',')\n",
        "\n",
        "#     for row in reader:\n",
        "#         tickers.append(row[0])\n",
        "\n",
        "# print(tickers[1:])\n",
        "\n",
        "# Get symbol data\n",
        "# Run ls to make sure you're in the right directory\n",
        "\n",
        "'''\n",
        "Put ourselves into the google drive directory for our project and get a list\n",
        "of symbols to use\n",
        "'''\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir(\"drive/My Drive/stock_project\")\n",
        "!ls\n",
        "raw_symbols = []\n",
        "symbols = []\n",
        "with open('symbols', 'r') as csvfile:\n",
        "  reader = csv.reader(csvfile, delimiter=',')\n",
        "\n",
        "  for row in reader:\n",
        "    raw_symbols.append(row)\n",
        "\n",
        "# symbols is a 2d list of one element, so make it the first element\n",
        "raw_symbols = raw_symbols[0]\n",
        "\n",
        "# sanitize symbols\n",
        "for symbol in raw_symbols:\n",
        "  if symbol.isalnum():\n",
        "    symbols.append(symbol)\n",
        "\n",
        "print(len(raw_symbols))\n",
        "print(len(symbols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "RDJTu0_vm41s"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Define our user agent so yahoo finance doesn't think we're a web crawler.\n",
        "Define the key parts of our URL to request\n",
        "'''\n",
        "header = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36'}\n",
        "\n",
        "head = 'https://finance.yahoo.com/quote/'\n",
        "stats_tail = '/key-statistics/'\n",
        "hist_tail = '/history/?period1=1559347200&period2=1717200000&interval=1mo&filter=history&frequency=1mo&includeAdjustedClose=true'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOsp0TpYoCf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b886be7-315c-4a1e-b029-ee64f4f2aec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://finance.yahoo.com/quote/A/key-statistics/\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "This cell is a prototype / test of fetching data from yahoo finance,\n",
        "to be used below.\n",
        "Make sure to run this to create table_elements\n",
        "'''\n",
        "\n",
        "\n",
        "# response = requests.get('https://finance.yahoo.com/quote/NVDA/key-statistics/', headers=header)\n",
        "response = requests.get(head + 'NVDA' + stats_tail, headers=header)\n",
        "print(head + symbols[0] + stats_tail)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "data_cells = soup.find_all('td')\n",
        "table_elements = []\n",
        "\n",
        "for tag in data_cells:\n",
        "  table_elements.append(tag.contents[0])\n",
        "print(table_elements)\n",
        "\n",
        "for i, s in enumerate(table_elements):\n",
        "  try:\n",
        "    if s[0].isalpha():\n",
        "      # print(f'{s}: {table_elements[i+1]}')\n",
        "      pass\n",
        "  except KeyError as error:\n",
        "    # print('--')\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEBDhEuDu68u"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This cell is a prototype / test of creation of the statistics dataframe,\n",
        "to be used below.\n",
        "'''\n",
        "\n",
        "cols = ['Company']\n",
        "d = {'Company': symbols[0]}\n",
        "for i, s in enumerate(table_elements):\n",
        "  try:\n",
        "    if s[0].isalpha():\n",
        "      cols.append(s)\n",
        "      d[s] = table_elements[i+1]\n",
        "  except KeyError:\n",
        "    cols.append(np.nan)\n",
        "\n",
        "df = pd.DataFrame(data=d, columns=cols, index=[0])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(head + 'A' + hist_tail, headers=header)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "data_cells = soup.find_all('td')\n",
        "table_elements = [tag.contents[0] for tag in data_cells]\n",
        "\n",
        "# # Get opening prices at the beginning of each month\n",
        "# for i in range(len(table_elements) - 1):\n",
        "#   table_elements[i] = str(table_elements[i])\n",
        "#   table_elements[i+1] = str(table_elements[i+1])\n",
        "#   if (table_elements[i][0].isalpha() and\n",
        "#       table_elements[i+1][0].isnumeric()):\n",
        "#     print(table_elements[i])\n",
        "#     print(table_elements[i+1])\n",
        "\n",
        "def append_stock_price(df, symbol, i):\n",
        "  response = requests.get(head + symbol + hist_tail, headers=header)\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  data_cells = soup.find_all('td')\n",
        "  table_elements = [tag.contents[0] for tag in data_cells]\n",
        "  company_price_df = pd.DataFrame(columns=['company', 'timestamp', 'close'])\n",
        "\n",
        "  if len(table_elements) == 0:\n",
        "    raise ConnectionError\n",
        "\n",
        "  for j in range(len(table_elements) - 1):\n",
        "    print('test')\n",
        "    try:\n",
        "      table_elements[j] = str(table_elements[j])\n",
        "      table_elements[j+1] = str(table_elements[j+1])\n",
        "      if (table_elements[j][0].isalpha() and\n",
        "          table_elements[j+1][0].isnumeric()):\n",
        "            d = {'company': symbol,\n",
        "                'timestamp': datetime.datetime.strptime(table_elements[j], \"%b %d, %Y\"),\n",
        "                'close': float(table_elements[j+1])}\n",
        "            print(d)\n",
        "\n",
        "            company_price_df = pd.concat([company_price_df, pd.DataFrame(d, index=[i])])\n",
        "            i += 1\n",
        "    except Exception as err:\n",
        "      print(f'{err}')\n",
        "\n",
        "  df = pd.concat([df, company_price_df])\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "uNCLvg7yO7Vo"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_df = pd.DataFrame(columns=['company', 'timestamp', 'close'])\n",
        "\n",
        "error_counter = 0\n",
        "\n",
        "for i in range(len(symbols)):\n",
        "  try:\n",
        "    price_df = append_stock_price(price_df, symbols[i], i)\n",
        "  except Exception as err:\n",
        "    error_counter += 1\n",
        "    print(f'{err}')\n",
        "\n",
        "  wait_time = 0\n",
        "  while pd.isna(price_df.close).iloc[-1]:\n",
        "    time.sleep(90 + wait_time)\n",
        "    wait_time += 1\n",
        "    price_df.drop()"
      ],
      "metadata": {
        "id": "76aUq7QmIk2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Esf4ctaFHT9"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Define our function for retriveing stock statistics (AKA data or valuations\n",
        "or metrics). Take in a DataFrame, create a new row for a new stock, and\n",
        "concatenate it onto the end of the DataFrame. Then return the new DataFrame.\n",
        "'''\n",
        "\n",
        "def append_stock_stats(df, symbol, i):\n",
        "  response = requests.get(head + symbol + stats_tail, headers=header)\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  data_cells = soup.find_all('td')\n",
        "  table_elements = []\n",
        "  d = {'Company': symbol}\n",
        "\n",
        "  for tag in data_cells:\n",
        "    try:\n",
        "      table_elements.append(tag.contents[0])\n",
        "    except IndexError as err:\n",
        "      table_elements.append(np.nan)\n",
        "      print(f'{err}')\n",
        "\n",
        "  for j, s in enumerate(table_elements):\n",
        "    try:\n",
        "      if s[0].isalpha() and j < len(table_elements) - 1:\n",
        "        d[s] = table_elements[j+1]\n",
        "    except KeyError:\n",
        "      # print(f'KeyError, Symbol: {symbol}, i: {i}')\n",
        "      # print(f'j: {j}, s: {s}')\n",
        "      pass\n",
        "    except IndexError:\n",
        "      print(f'IndexError, Symbol: {symbol}, i: {i}, j: {j}')\n",
        "      print(f'j: {j}, s: {s}')\n",
        "      raise\n",
        "    except TypeError:\n",
        "      print(f'TypeError, Symbol: {symbol}, i: {i}, j: {j}')\n",
        "      print(f'j: {j}, s: {s}')\n",
        "      raise\n",
        "    except requests.TooManyRedirects:\n",
        "      print(f'TooManyRedirects, Symbol: {symbol}, i: {i}, j: {j}')\n",
        "      print(f'j: {j}, s: {s}')\n",
        "      raise\n",
        "\n",
        "  row = pd.DataFrame(data=d, columns=cols, index=[i])\n",
        "  df = pd.concat([df, row])\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkqz0O-KHNJ2"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Create and populate our DataFrame of stock data.\n",
        "Note this cell takes about 12 hours to run :)\n",
        "'''\n",
        "\n",
        "# Create columns for reference\n",
        "cols = ['Company']\n",
        "for s in table_elements:\n",
        "  try:\n",
        "    if s[0].isalpha():\n",
        "      cols.append(s)\n",
        "  except KeyError:\n",
        "    cols.append(np.nan)\n",
        "\n",
        "# Create empty DataFrame with just column names\n",
        "df = pd.DataFrame(columns=cols)\n",
        "\n",
        "# Populate the DataFrame\n",
        "symbol_index = 100\n",
        "df_num = 58\n",
        "for i in range(0, len(symbols)):\n",
        "  try:\n",
        "    df = append_stock_stats(df, symbols[i], i)\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "\n",
        "  # In case we've used up our allotted requests per whatever,\n",
        "  # we wait, then delete the last row and try again\n",
        "  wait_time = 0\n",
        "  while pd.isna(df['Market Cap'].iloc[-1]):\n",
        "    time.sleep(90 + wait_time)\n",
        "    wait_time += 1\n",
        "    df.drop(df.tail(1).index, inplace=True)\n",
        "    try:\n",
        "      df = append_stock_stats(df, symbols[i], i)\n",
        "    # If for whatever reason we can't get a particular stock's data\n",
        "    # we continue on without it's data\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "  print(f'Row {i} fetched, Current stock: {symbols[i]}')\n",
        "\n",
        "  if i % 100 == 0:\n",
        "    !ls\n",
        "\n",
        "  if i % 99 == 0 and i > 0:\n",
        "    filename = f'df{df_num}.csv'\n",
        "    df_num += 1\n",
        "    df.to_csv(filename)\n",
        "    df = pd.DataFrame(columns=cols)\n",
        "    print(f'stocks {i-100} through {i} written')\n",
        "    !ls\n",
        "\n",
        "\n",
        "  # # Add a random delay because I am unreasonably cautious about getting\\\n",
        "  # # banned from yahoo finance\n",
        "  delay = random.random() * 0.5 + 0.5\n",
        "  time.sleep(delay)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkcWQesjhtRe"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Get the stock metrics csv and clean it up a little. It will be cleaned more after\n",
        "the stock prices have been added\n",
        "'''\n",
        "\n",
        "copy = pd.read_csv('df.csv', index_col=0)\n",
        "\n",
        "for i in range(3, 67):\n",
        "  df = pd.read_csv(f'df{i}.csv', index_col=0)\n",
        "  copy = pd.concat([copy, df], axis=0, join='outer')\n",
        "  print(copy.shape)\n",
        "\n",
        "df = pd.read_csv('1585through1588.csv')\n",
        "copy = pd.concat([copy, df], axis=0, join='outer')\n",
        "df = pd.read_csv('496through499.csv')\n",
        "copy = pd.concat([copy, df], axis=0, join='outer')\n",
        "\n",
        "copy.reset_index()\n",
        "copy.drop(columns=['Unnamed: 0', 'Unnamed: 11'])\n",
        "copy.to_csv('df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUPx9lHQrkOL"
      },
      "outputs": [],
      "source": [
        "def string_to_dollar(value: str) -> int:\n",
        "  if type(value) != str or value[:2] == '--':\n",
        "    return np.NaN\n",
        "\n",
        "  pre_decimal = 0\n",
        "  post_decimal = 0\n",
        "  figures = {'': 1,\n",
        "             'k': 1000,\n",
        "             'M': 1000000,\n",
        "             'B': 1000000000,\n",
        "             'T': 1000000000000}\n",
        "  i = 0\n",
        "  j = 1\n",
        "\n",
        "  while i < len(value) and value[i].isnumeric():\n",
        "    pre_decimal = pre_decimal * 10 + int(value[i])\n",
        "    i += 1\n",
        "\n",
        "  while i < len(value) and not value[i].isalpha():\n",
        "    if value[i].isnumeric():\n",
        "      post_decimal += int(value[i]) / 10**j\n",
        "      j += 1\n",
        "    i += 1\n",
        "\n",
        "  try:\n",
        "    if value[0] == '-':\n",
        "      return -1 * (pre_decimal + post_decimal) * figures[value[i]]\n",
        "    return (pre_decimal + post_decimal) * figures[value[i]]\n",
        "\n",
        "  # IMPORTANT: This will only be called if the string is of the form x,yyy.zz\n",
        "  # i.e. it will NOT be called when there is a letter from the figures dict\n",
        "  # in it, so we do not need to use the figures dict\n",
        "  except:\n",
        "    if value[0] == '-':\n",
        "      return -1 * float(value.replace(',', '').strip())\n",
        "    return float(value.replace(',', '').strip())\n",
        "\n",
        "# TEST CASES:\n",
        "# print(string_to_dollar('666.56K')) Random one with K instead of M\n",
        "# print(string_to_dollar('38.81B')) A\n",
        "# print(string_to_dollar('7.39B')) AA\n",
        "# print(string_to_dollar('666.56M')) AACT\n",
        "# print(string_to_dollar('2.96T')) AAPL\n",
        "# print(string_to_dollar('--')) None fetched / avaliable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vaPGa2jN-HB"
      },
      "outputs": [],
      "source": [
        "def string_to_percent(value):\n",
        "  if type(value) != str or value[:2] == '--':\n",
        "    return np.NaN\n",
        "\n",
        "  value = value.strip()\n",
        "  res_string = ''\n",
        "  for c in value:\n",
        "    if c != ',' and c != '%':\n",
        "      res_string += c\n",
        "\n",
        "  return float(res_string)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcY3TnvWoi31"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Clean up our training data DataFrame\n",
        "'''\n",
        "\n",
        "df = pd.read_csv('df.csv', index_col=0)\n",
        "# Drop rows incorrectly added\n",
        "df.drop(columns=['Unnamed: 0', 'Unnamed: 11'], inplace=True)\n",
        "\n",
        "# Convert from object to string dtypes for all columns\n",
        "df = df.convert_dtypes()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "df.drop(columns=['Most Recent Quarter  (mrq)', 'Last Split Factor '],\n",
        "        inplace=True)\n",
        "\n",
        "# Rename some columns with weird whitespace stuff\n",
        "df.rename(columns={col : col.replace(\" (\", \"(\").strip() for col in df.columns},\n",
        "            inplace=True)\n",
        "\n",
        "# In the dollar columns, convert from string to float (which can be dollars\n",
        "# or something else)\n",
        "dollar_cols = ['Market Cap', 'Enterprise Value', 'Trailing P/E', 'Forward P/E',\n",
        "               'PEG Ratio(5yr expected)', 'Price/Sales', 'Price/Book',\n",
        "               'Enterprise Value/Revenue', 'Revenue Per Share (ttm)',\n",
        "               'Gross Profit (ttm)', 'EBITDA', 'Net Income Avi to Common (ttm)',\n",
        "               'Diluted EPS (ttm)', 'Total Cash (mrq)',\n",
        "               'Total Cash Per Share (mrq)', 'Total Debt (mrq)',\n",
        "               'Current Ratio (mrq)', 'Book Value Per Share (mrq)',\n",
        "               'Operating Cash Flow (ttm)', 'Levered Free Cash Flow (ttm)',\n",
        "               'Beta(5Y Monthly)', 'Avg Vol(3 month)', 'Shares Outstanding',\n",
        "               'Implied Shares Outstanding', 'Float', 'Shares Short(5/15/2024)',\n",
        "               'Short Ratio(5/15/2024)', 'Shares Short(prior month 4/15/2024)',\n",
        "               'Forward Annual Dividend Rate', 'Trailing Annual Dividend Rate']\n",
        "for column in dollar_cols:\n",
        "  df[column] = df[column].apply(string_to_dollar)\n",
        "\n",
        "# In the datetime columns, convert from string to datetime\n",
        "datetime_cols = ['Fiscal Year Ends', 'Dividend Date', 'Ex-Dividend Date',\n",
        "                 'Last Split Date']\n",
        "for column in datetime_cols:\n",
        "  df[column] = pd.to_datetime(df[column], errors='coerce')\n",
        "\n",
        "# In the percentage columns, convert from string to float\n",
        "percentage_cols = ['Profit Margin', 'Operating Margin (ttm)',\n",
        "                   'Return on Assets (ttm)', 'Return on Equity (ttm)',\n",
        "                   'Quarterly Revenue Growth (yoy)',\n",
        "                   'Quarterly Earnings Growth (yoy)',\n",
        "                   'Total Debt/Equity (mrq)', 'S&P 500 52-Week Change',\n",
        "                   'Short % of Float(5/15/2024)',\n",
        "                   'Short % of Shares Outstanding(5/15/2024)',\n",
        "                   'Forward Annual Dividend Yield',\n",
        "                   'Trailing Annual Dividend Yield', 'Payout Ratio']\n",
        "for column in percentage_cols:\n",
        "  df[column] = df[column].apply(string_to_percent)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORgzCcwPUFsLc2bg53/msw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}